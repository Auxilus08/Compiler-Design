{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNnnhba0yOVLnaMYF+L/H0c",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Auxilus08/Compiler-Design/blob/main/Cd_practical3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parser Construction"
      ],
      "metadata": {
        "id": "VP16yxTY9L9Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "grammer = {}\n",
        "non_terminals = set()\n",
        "first_sets = {}\n"
      ],
      "metadata": {
        "id": "jkWlxU5bEYsA"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "nU2TK6te9Jeh"
      },
      "outputs": [],
      "source": [
        "def parse_grammer(input_lines):\n",
        "  grammer.clear()\n",
        "  non_terminals.clear()\n",
        "\n",
        "  for line in input_lines:\n",
        "    line = line.strip()\n",
        "    if not line or line.startswith('#'):\n",
        "      continue\n",
        "    head, _, str_productions = line.partition(':')\n",
        "    head = head.strip()\n",
        "\n",
        "    if not head.isupper():\n",
        "      print(f\" Non terminal {head} is not uppercase.\")\n",
        "\n",
        "    non_terminals.add(head)\n",
        "\n",
        "    if head not in grammer:\n",
        "      grammer[head] = []\n",
        "\n",
        "    productions = str_productions.split('|')\n",
        "    for production in productions:\n",
        "      production = production.strip()\n",
        "      grammer[head].append(production.split()) # Split production into symbols"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_first_for_sequence(sequence):\n",
        "  first = set()\n",
        "\n",
        "  if not sequence or (len(sequence) == 1 and sequence[0] == 'Epsilon'): # Handle single 'Epsilon'\n",
        "    return {'Epsilon'}\n",
        "\n",
        "  can_produce_epsilon = True\n",
        "\n",
        "  for symbol in sequence:\n",
        "    if symbol not in non_terminals:\n",
        "      first.add(symbol)\n",
        "      can_produce_epsilon = False\n",
        "      break\n",
        "\n",
        "    first_of_symbol = first_sets.get(symbol, set()) # Use .get() with empty set default\n",
        "    first.update(first_of_symbol - {'Epsilon'})\n",
        "\n",
        "    if 'Epsilon' not in first_of_symbol:\n",
        "      can_produce_epsilon = False\n",
        "      break\n",
        "\n",
        "  if can_produce_epsilon:\n",
        "    first.add('Epsilon')\n",
        "\n",
        "  return first"
      ],
      "metadata": {
        "id": "GLKlUknq96gh"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_first_set():\n",
        "\n",
        "  for nt in non_terminals:\n",
        "    first_sets[nt] = set()\n",
        "\n",
        "  while True:\n",
        "    changed = False\n",
        "\n",
        "    for nt in non_terminals:\n",
        "      original_size = len(first_sets[nt])\n",
        "\n",
        "      for production in grammer.get(nt, []):\n",
        "        first_of_rhs = calculate_first_for_sequence(production)\n",
        "        first_sets[nt].update(first_of_rhs)\n",
        "\n",
        "      if len(first_sets[nt]) != original_size:\n",
        "        changed = True\n",
        "\n",
        "    if not changed:\n",
        "      break"
      ],
      "metadata": {
        "id": "yunp5y1KBfU5"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "  print(\"Enter the Grammer Rules: \")\n",
        "  print(\"use 'Epsilon'. press Enter on an Empty line when you are done\")\n",
        "  print(\"-\" * 20)\n",
        "\n",
        "  input_lines = []\n",
        "  while True:\n",
        "    try:\n",
        "      line = input()\n",
        "      if not line:\n",
        "        break\n",
        "      input_lines.append(line)\n",
        "\n",
        "    except EOFError:\n",
        "      break\n",
        "\n",
        "  if not input_lines:\n",
        "    print(\"No grammer rules for Entered. Exiting\")\n",
        "    return\n",
        "\n",
        "  try:\n",
        "    parse_grammer(input_lines)\n",
        "    compute_first_set()\n",
        "\n",
        "    sorted_nts = sorted(list(non_terminals))\n",
        "    for nt in sorted_nts:\n",
        "            terminals_str = \", \".join(sorted(list(first_sets.get(nt, set()))))\n",
        "            print(f\"FIRST({nt}) = {{ {terminals_str} }}\")\n",
        "\n",
        "  except Exception as e:\n",
        "        print(f\"\\nAn error occurred: {e}\", file=sys.stderr)\n",
        "\n"
      ],
      "metadata": {
        "id": "JYhbU8UKCMGS"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "outputId": "d0eb9b7e-8460-42ca-d4dd-15fc4e1eccc4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AeJArOhCEszK"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the Grammer Rules: \n",
            "use 'Epsilon'. press Enter on an Empty line when you are done\n",
            "--------------------\n",
            "A : S B | B\n",
            "B : b | d\n",
            "S : a | B c | Epsilon\n",
            "\n",
            "FIRST(A) = { a, b, d }\n",
            "FIRST(B) = { b, d }\n",
            "FIRST(S) = { Epsilon, a, b, d }\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2XJauWiZDQEa"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ghkx9pTsDQz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4ed0dd6"
      },
      "source": [
        "# Task\n",
        "Fix the provided Python code to correctly calculate the FOLLOW sets and construct the LL(1) parsing table for the given grammar, using the previously computed FIRST sets. Display the calculated FOLLOW sets and the resulting LL(1) parsing table."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5abce7e"
      },
      "source": [
        "## Compute follow sets\n",
        "\n",
        "### Subtask:\n",
        "\n",
        "Define a function to compute the FOLLOW sets for each non-terminal using the previously computed FIRST sets and the grammar rules."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5850eeec"
      },
      "source": [
        "def compute_follow_set():\n",
        "  follow_sets = {nt: set() for nt in non_terminals}\n",
        "  start_symbol = list(grammer.keys())[0]\n",
        "  follow_sets[start_symbol].add('$')\n",
        "\n",
        "  changed = True\n",
        "  while changed:\n",
        "    changed = False\n",
        "    for head, productions in grammer.items():\n",
        "      for production in productions:\n",
        "        for i, symbol in enumerate(production):\n",
        "          if symbol in non_terminals:\n",
        "            beta = production[i+1:]\n",
        "            first_of_beta = calculate_first_for_sequence(beta)\n",
        "\n",
        "            original_size = len(follow_sets[symbol])\n",
        "            follow_sets[symbol].update(first_of_beta - {'Epsilon'})\n",
        "\n",
        "            if 'Epsilon' in first_of_beta or not beta:\n",
        "              follow_sets[symbol].update(follow_sets[head])\n",
        "\n",
        "            if len(follow_sets[symbol]) != original_size:\n",
        "              changed = True\n",
        "  return follow_sets"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ce063f0"
      },
      "source": [
        "## Construct ll(1) parsing table\n",
        "\n",
        "### Subtask:\n",
        "Define a function to construct the LL(1) parsing table using the computed FIRST and FOLLOW sets.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f599c915"
      },
      "source": [
        "def construct_ll1_table(grammer, first_sets, follow_sets):\n",
        "  parsing_table = {}\n",
        "\n",
        "  terminals = set()\n",
        "  for productions in grammer.values():\n",
        "    for production in productions:\n",
        "      for symbol in production:\n",
        "        if symbol not in non_terminals and symbol != 'Epsilon':\n",
        "          terminals.add(symbol)\n",
        "  terminals.add('$')\n",
        "\n",
        "\n",
        "  for nt in non_terminals:\n",
        "    parsing_table[nt] = {}\n",
        "    for t in terminals:\n",
        "      parsing_table[nt][t] = None # Initialize with None for error indication\n",
        "\n",
        "\n",
        "  for head, productions in grammer.items():\n",
        "    for production in productions:\n",
        "      first_of_rhs = calculate_first_for_sequence(production)\n",
        "\n",
        "      if 'Epsilon' in first_of_rhs:\n",
        "        for terminal in follow_sets.get(head, set()):\n",
        "           if parsing_table[head][terminal] is not None:\n",
        "             print(f\"Conflict at M[{head}, {terminal}]\")\n",
        "           parsing_table[head][terminal] = production\n",
        "      else:\n",
        "        for terminal in first_of_rhs:\n",
        "          if terminal != 'Epsilon':\n",
        "            if parsing_table[head][terminal] is not None:\n",
        "              print(f\"Conflict at M[{head}, {terminal}]\")\n",
        "            parsing_table[head][terminal] = production\n",
        "\n",
        "  return parsing_table"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "599b2c4a"
      },
      "source": [
        "## Present results\n",
        "\n",
        "### Subtask:\n",
        "Display the computed FOLLOW sets and the constructed LL(1) parsing table.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ead02810",
        "outputId": "fd03d553-0a8c-4053-96ac-81da3850127c"
      },
      "source": [
        "follow_sets = compute_follow_set()\n",
        "parsing_table = construct_ll1_table(grammer, first_sets, follow_sets)\n",
        "\n",
        "print(\"\\nFOLLOW Sets:\")\n",
        "print(\"-\" * 20)\n",
        "sorted_nts = sorted(list(non_terminals))\n",
        "for nt in sorted_nts:\n",
        "    terminals_str = \", \".join(sorted(list(follow_sets.get(nt, set()))))\n",
        "    print(f\"FOLLOW({nt}) = {{ {terminals_str} }}\")\n",
        "\n",
        "print(\"\\nLL(1) Parsing Table:\")\n",
        "print(\"-\" * 20)\n",
        "\n",
        "terminals = set()\n",
        "for productions in grammer.values():\n",
        "    for production in productions:\n",
        "        for symbol in production:\n",
        "            if symbol not in non_terminals and symbol != 'Epsilon':\n",
        "                terminals.add(symbol)\n",
        "terminals.add('$')\n",
        "sorted_terminals = sorted(list(terminals))\n",
        "\n",
        "header = \"{:<10}\".format(\"Non-Terminal\")\n",
        "for t in sorted_terminals:\n",
        "    header += \"{:<10}\".format(t)\n",
        "print(header)\n",
        "print(\"-\" * (10 * (len(sorted_terminals) + 1)))\n",
        "\n",
        "for nt in sorted_nts:\n",
        "    row = \"{:<10}\".format(nt)\n",
        "    for t in sorted_terminals:\n",
        "        production = parsing_table.get(nt, {}).get(t)\n",
        "        if production is not None:\n",
        "            production_str = \" \".join(production)\n",
        "            row += \"{:<10}\".format(f\"{nt} -> {production_str}\")\n",
        "        else:\n",
        "            row += \"{:<10}\".format(\"\")\n",
        "    print(row)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conflict at M[A, d]\n",
            "Conflict at M[A, b]\n",
            "Conflict at M[S, d]\n",
            "Conflict at M[S, b]\n",
            "\n",
            "FOLLOW Sets:\n",
            "--------------------\n",
            "FOLLOW(A) = { $ }\n",
            "FOLLOW(B) = { $, c }\n",
            "FOLLOW(S) = { b, d }\n",
            "\n",
            "LL(1) Parsing Table:\n",
            "--------------------\n",
            "Non-Terminal$         a         b         c         d         \n",
            "------------------------------------------------------------\n",
            "A                   A -> S B  A -> B              A -> B    \n",
            "B                             B -> b              B -> d    \n",
            "S                   S -> a    S -> Epsilon          S -> Epsilon\n"
          ]
        }
      ]
    }
  ]
}